Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job            count    min threads    max threads
-----------  -------  -------------  -------------
simple_rule        1              1              1
total              1              1              1

Select jobs to execute...

[Tue Mar 15 11:29:20 2022]
rule simple_rule:
    input: scr/data/testData.rds
    output: out/testOutput.rds
    jobid: 0
    resources: tmpdir=/var/folders/12/8nyhyysj71726krwt80366q80000gr/T

[Tue Mar 15 11:29:20 2022]
Error in rule simple_rule:
    jobid: 0
    output: out/testOutput.rds

RuleException:
WorkflowError in line 9 of /Users/frbayer/Documents/phd_main/projects/graph-based-clustering/snakemake/workflow/Snakefile:
Failed to open source file /Users/frbayer/Documents/phd_main/projects/graph-based-clustering/snakemake/workflow/scr/data-processing/simple-test-script.R
FileNotFoundError: [Errno 2] No such file or directory: '/Users/frbayer/Documents/phd_main/projects/graph-based-clustering/snakemake/workflow/scr/data-processing/simple-test-script.R'
  File "/Users/frbayer/Documents/phd_main/projects/graph-based-clustering/snakemake/workflow/Snakefile", line 9, in __rule_simple_rule
  File "/Users/frbayer/mambaforge/envs/snakemake/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/frbayer/Documents/phd_main/projects/graph-based-clustering/snakemake/.snakemake/log/2022-03-15T112920.069411.snakemake.log
